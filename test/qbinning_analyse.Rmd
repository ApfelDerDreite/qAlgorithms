---
title: "Analysis qbinning"
author: "Daniel Höhn"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# knitr::opts_knit$set(root.dir = "G:/_Studium/Analytik-Praktikum/qbinning")
library(tidyverse)
library(data.table)
library(patchwork)
library(TeachingDemos)
library(pracma)

makeDQS <- function(MID, MOD){
  dqs = (MOD - MID) * (1 / (1 + MID)) / max(MID, MOD)
  dqs = (dqs + 1) / 2
  return(dqs)
}
critVal <- function(n){
  ## Function generating the critical mz difference using order statistics
  
  critVal <- 3.05037165842070*log(n)^(-0.4771864667153)
  return(critVal)
}
```

```{r new bin}
monobin = read.csv("../../rawdata/monobin_base.csv")
monobin = monobin[which(1912 < monobin$scans & monobin$scans < 1958),]

# erstelle je 1 Eintrag für alle scans zwischen 1913 und 1957
for (i in 1913:1957) {
  r = runif(1, 2, 4)
  a = c(55*r, r*r/1000000, runif(1, 700, 2000), i, 1, -1, 0, -1)
  monobin = rbind(monobin, a)
}
for (i in 1:length(monobin$mz)) {
  t1 = c(monobin$mz[i]*runif(1, 2, 3), monobin$error[i], NA, monobin$scans[i], 1, -1, 0, -1)
  t2 = c(monobin$mz[i]*runif(1, 2, 4), monobin$error[i], NA, monobin$scans[i], 1, -1, 0, -1)
  monobin = rbind(monobin, t1)
  monobin = rbind(monobin, t2)
}
monobin$rt = monobin$scans * 0.65
monobin = monobin[with(monobin, order(scans, mz)), ]

# write.csv(monobin, "../../rawdata/monobin.csv", row.names = FALSE)

# für R:
monoR = read.csv("../../rawdata/monobin.csv")[,-8]
write.csv(monoR, "../../rawdata/monobinForR.csv", row.names = FALSE)

```

```{r artificial bin}
artmz = rep(c(200,300,400), each = 10)
artmz = artmz + runif(30, 0.0001, 0.0009)
arterror = artmz * 0.000005
artscan = c(1:10, 6:15, 11:20)

artbin = data.frame(mz = artmz, error = arterror, rt = NA, scans = artscan, intensity = 1, ID = c(rep(1:3, each = 10)), DQScen = 0.99, DQSbin = 0.99)

out1 = c(215, 0.001, NA, 2, 1, 0, 0.1, 0.1)
out2 = c(300.5, 0.0015, NA, 20, 1, 0, 0.1, 0.1)

artbin = rbind(artbin, out1, out2)
artbin$rt = 0.65 * artbin$scans + 1

# write.csv(artbin, "../../rawdata/artbin.csv", row.names = FALSE)
```



```{r bin results}
Rprof(tf <- "log.log", memory.profiling = TRUE)
# the code you want to profile must be in between

qbins <- read.csv("../../qbinning_binlist.csv")
accurate = c(1:16)

for (i in 0:15) {
  accurate[i+1] = sum((round(qbins$DQS - qbins$control_DQSB, digits = i) == 0))
}

plot(c(0:15), accurate/length(qbins$mz))
plot(c(0:15), cumsum(accurate))

qbins$DQSacc = qbins$DQS - qbins$control_DQSB

plot(round(qbins$control_DQSB, digits = 3), round(qbins$DQS, digits = 3))

Rprof (NULL) ; print(summaryRprof(tf))

```

```{r control notbinned}
# outliers should be normally distributed throughout the dataset
notbinned = read.csv("../../qbinning_notbinned.csv")[,1:2]

```

```{r control median of mz}
medianMZ = read.csv("../../qbins_tvals.csv")
medianMZ$critTval = qt(0.05, medianMZ$n, lower.tail = FALSE)
medianMZ$check = medianMZ$critTval - medianMZ$tval
sum(medianMZ$check < 0)
hist(log10(medianMZ$n[which(medianMZ$check < 0)])) # no strict correlation between binsize, dqs and the median being a bad estimate of the distribution mean
```

```{r merge}
prebinned <- read.csv("../../rawdata/control_bins_base.csv")
rawdata <- read.csv("../../rawdata/qCentroid_Warburg_pos_171123_01_Zu_01.csv")
prebinned$mzError <- rawdata$Centroid.Error
#mz column, centroid error column, RT column, scan number column, control ID column 
export <- data.frame(mz = prebinned$mz, mzError = prebinned$mzError, RT = prebinned$rt, scanNo = prebinned$scanNo, intensity = prebinned$intensity, controlID = prebinned$ID, controlCentroidDQS = prebinned$DQScen, controlBinDQS = prebinned$DQSbin)

write.csv(export, "../../rawdata/control_bins_full.csv", row.names = FALSE)
getwd()
```

```{r check bin summary}
summary <- read.csv("../../summary_bins.csv")
accurate = c(1:16)

for (i in 0:15) {
  accurate[i+1] = sum((round(summary$DQSB - summary$DQSB_control, digits = i) == 0))
}

plot(c(0:15), accurate/length(summary$ID))
plot(summary$DQSB, summary$DQSB_worst) 
sum((summary$DQSB - summary$DQSB_worst) < 0)

summary[which((summary$DQSB - summary$DQSB_worst) < 0),] # for some points, the worst DQS is better than the actual one - why?
hist(summary$stdev_mz[which((summary$DQSB - summary$DQSB_worst) < 0)])

hist(abs(summary$mean_scans - summary$median_scans))
sum((abs(summary$mean_scans - summary$median_scans)) > 6) # 1005

```

```{r error analysis}
points_total = 3568033
bins_total = 55910

summary_error <- read.csv("../../selectbins_summary.csv")
bins_error <- read.csv("../../selectbins_full.csv")

summary_error = summary_error[order(summary_error$mean_mz),]

stats = as.data.frame(table(summary_error$errorcode)) # alle ungeraden Zahlen haben duplikate
stats$Var1 = as.numeric(levels(stats$Var1))
stats$Var1 = as.numeric(lapply(stats$Var1, bits))
stats$Freq = as.numeric(stats$Freq)

stats[stats$Var1 %% 2 != 0,]
 
stats[stats$Var1 - round(stats$Var1, -2) >= 10,] # Seltsame DQS korrelierern nicht mit anderen Fehlern

# MZ außerhalb 3 sigma korreliert mit 
stats[stats$Var1 >= 10000,]

summary_error$errorcode = as.numeric(lapply(summary_error$errorcode, bits))

ggplot(summary_error)+
  geom_point(aes(x = mean_mz, y = mean_scans, colour = as.factor(errorcode)))

summary_error %>% group_by(errorcode) %>% summarise(bin_count = n(), total_points = sum(size), ratio = sum(size)/n())

bins_error[bins_error$ID == 308,]
minDists308 = c(6.2961233993519272e-05, 8.8906114996234464e-05, 9.4137318995990427e-05, 0.0001178799969920874, 8.2152471009067085e-05, 7.1812920992897489e-05)
errors308 = c(2.62158179102052e-05, 0.000221785977937405, 1.7943534787886702e-05, 3.6100375305253397e-05, 1.8813454471750598e-05, 7.20372773346827e-05)
MIDs308 = fast_mean_distance(bins_error[bins_error$ID == 308,1])
maxdist308 = critVal(6) * mean(errors308)
maxdist308_7 = critVal(7) * mean(errors308)

for (i in 1:6) {
  print(sprintf("%0.10f /// %0.10f", makeDQS(MIDs308[i], minDists308[i]), makeDQS(MIDs308[i], maxdist308)))
}
```

